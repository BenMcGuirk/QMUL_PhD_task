{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNotebook for logistic regression\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Notebook for logistic regression\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from src.modelling.logistic_regression.logistic_cost_function import logistic_cost_function\n",
    "from src.modelling.logistic_regression.logistic_hypothesis_function import sigmoid\n",
    "from src.modelling.logistic_regression.logistic_gradient_descent import logistic_gradient_descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        AGE       BMI   density\n",
      "0  2.349969 -0.001759 -0.453182\n",
      "1  0.119025 -0.168809 -0.957611\n",
      "2  2.864802 -0.455181  0.051246\n",
      "3 -1.425474 -0.693824 -0.116897\n",
      "4 -0.395808 -0.550638  1.060103\n",
      "        AGE       BMI   density\n",
      "0 -0.297527 -0.212745  0.046396\n",
      "1  2.581536  0.013392 -0.118026\n",
      "2 -0.117585 -0.715271  1.032928\n",
      "3 -0.117585  1.772234 -1.597824\n",
      "4  2.041712  1.118950 -0.940136\n",
      "        AGE       BMI   density\n",
      "0  2.270235  0.102744 -1.537497\n",
      "1  1.099942 -1.324573  0.816613\n",
      "2 -1.742196 -0.767027 -1.201196\n",
      "3 -1.240642  2.778963 -0.696743\n",
      "4 -0.906273  1.217835 -1.537497\n"
     ]
    }
   ],
   "source": [
    "# Load data from Excel files\n",
    "train_data = pd.read_excel('../../data/preprocessed/train_data.xlsx')\n",
    "cv_data = pd.read_excel('../../data/preprocessed/cv_data.xlsx')\n",
    "test_data = pd.read_excel('../../data/preprocessed/test_data.xlsx')\n",
    "# Print the first 5 rows of each data set\n",
    "print(train_data.head())\n",
    "print(cv_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target variable (y) and features (X)\n",
    "y_train = train_data['']\n",
    "X_train = train_data.drop('target_column', axis=1)\n",
    "\n",
    "y_cv = cv_data['target_column']\n",
    "X_cv = cv_data.drop('target_column', axis=1)\n",
    "\n",
    "y_test = test_data['target_column']\n",
    "X_test = test_data.drop('target_column', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column of ones to the feature matrices for the bias term\n",
    "X_train = np.column_stack((np.ones(len(X_train)), X_train))\n",
    "X_cv = np.column_stack((np.ones(len(X_cv)), X_cv))\n",
    "X_test = np.column_stack((np.ones(len(X_test)), X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "theta = np.zeros(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "alpha = 0.01\n",
    "num_iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using gradient descent\n",
    "theta = logistic_gradient_descent(X_train, y_train, theta, alpha, num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on training, cv, and test sets\n",
    "y_train_pred = sigmoid(np.dot(X_train, theta))\n",
    "y_cv_pred = sigmoid(np.dot(X_cv, theta))\n",
    "y_test_pred = sigmoid(np.dot(X_test, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cost on training, cv, and test sets\n",
    "cost_train = logistic_cost_function(y_train, y_train_pred)\n",
    "cost_cv = logistic_cost_function(y_cv, y_cv_pred)\n",
    "cost_test = logistic_cost_function(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Final theta: {theta}\")\n",
    "print(f\"Cost on training set: {cost_train}\")\n",
    "print(f\"Cost on cross-validation set: {cost_cv}\")\n",
    "print(f\"Cost on test set: {cost_test}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
