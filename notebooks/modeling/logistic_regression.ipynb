{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Notebook for logistic regression\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from logistic_cost_function import logistic_cost_function\n",
    "from logistic_cost_function import sigmoid\n",
    "from logistic_gradient_descent import logistic_gradient_descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from Excel files\n",
    "train_data = pd.read_excel('train_data.xlsx')\n",
    "cv_data = pd.read_excel('cv_data.xlsx')\n",
    "test_data = pd.read_excel('test_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target variable (y) and features (X)\n",
    "y_train = train_data['target_column']\n",
    "X_train = train_data.drop('target_column', axis=1)\n",
    "\n",
    "y_cv = cv_data['target_column']\n",
    "X_cv = cv_data.drop('target_column', axis=1)\n",
    "\n",
    "y_test = test_data['target_column']\n",
    "X_test = test_data.drop('target_column', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column of ones to the feature matrices for the bias term\n",
    "X_train = np.column_stack((np.ones(len(X_train)), X_train))\n",
    "X_cv = np.column_stack((np.ones(len(X_cv)), X_cv))\n",
    "X_test = np.column_stack((np.ones(len(X_test)), X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "theta = np.zeros(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "alpha = 0.01\n",
    "num_iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using gradient descent\n",
    "theta = logistic_gradient_descent(X_train, y_train, theta, alpha, num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on training, cv, and test sets\n",
    "y_train_pred = sigmoid(np.dot(X_train, theta))\n",
    "y_cv_pred = sigmoid(np.dot(X_cv, theta))\n",
    "y_test_pred = sigmoid(np.dot(X_test, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cost on training, cv, and test sets\n",
    "cost_train = logistic_cost_function(y_train, y_train_pred)\n",
    "cost_cv = logistic_cost_function(y_cv, y_cv_pred)\n",
    "cost_test = logistic_cost_function(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Final theta: {theta}\")\n",
    "print(f\"Cost on training set: {cost_train}\")\n",
    "print(f\"Cost on cross-validation set: {cost_cv}\")\n",
    "print(f\"Cost on test set: {cost_test}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
